{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 230130 entries, 0 to 230129\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   id        230130 non-null  int64  \n",
      " 1   date      230130 non-null  object \n",
      " 2   country   230130 non-null  object \n",
      " 3   store     230130 non-null  object \n",
      " 4   product   230130 non-null  object \n",
      " 5   num_sold  221259 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 10.5+ MB\n",
      "None\n",
      "                  id       num_sold\n",
      "count  230130.000000  221259.000000\n",
      "mean   115064.500000     752.527382\n",
      "std     66432.953062     690.165445\n",
      "min         0.000000       5.000000\n",
      "25%     57532.250000     219.000000\n",
      "50%    115064.500000     605.000000\n",
      "75%    172596.750000    1114.000000\n",
      "max    230129.000000    5939.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98550 entries, 0 to 98549\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       98550 non-null  int64 \n",
      " 1   date     98550 non-null  object\n",
      " 2   country  98550 non-null  object\n",
      " 3   store    98550 non-null  object\n",
      " 4   product  98550 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "                  id\n",
      "count   98550.000000\n",
      "mean   279404.500000\n",
      "std     28449.078852\n",
      "min    230130.000000\n",
      "25%    254767.250000\n",
      "50%    279404.500000\n",
      "75%    304041.750000\n",
      "max    328679.000000\n"
     ]
    }
   ],
   "source": [
    "#data exploration\n",
    "print(train.info())\n",
    "print(train.describe())\n",
    "print(test.info())\n",
    "print(test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "date        0\n",
      "country     0\n",
      "store       0\n",
      "product     0\n",
      "num_sold    0\n",
      "dtype: int64\n",
      "id         0\n",
      "date       0\n",
      "country    0\n",
      "store      0\n",
      "product    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#showing null values\n",
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling missing values\n",
    "train['num_sold'] = train['num_sold'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usuń wiersze z brakującymi wartościami w 'num_sold' zarówno z x, jak i y\n",
    "train = train.dropna(subset=['num_sold'])\n",
    "\n",
    "# Zaktualizuj zmienne x i y po usunięciu brakujących danych\n",
    "x = train.drop(columns=['id', 'num_sold'], axis=1)\n",
    "y = train['num_sold']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "Index(['country', 'store', 'product'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#pipeline for preprocessing\n",
    "numeric_features = x.select_dtypes(include=['int64','float64']).columns\n",
    "categorical_features = x.select_dtypes(include=['object']).columns\n",
    "categorical_features = categorical_features[categorical_features != 'date']\n",
    "\n",
    "\n",
    "print(numeric_features)\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konwersja kolumny daty na cechy numeryczne\n",
    "x['year'] = pd.to_datetime(x['date']).dt.year\n",
    "x['month'] = pd.to_datetime(x['date']).dt.month\n",
    "x['day'] = pd.to_datetime(x['date']).dt.day\n",
    "\n",
    "# Usuń oryginalną kolumnę daty\n",
    "X = x.drop(columns=['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "#preprocessor \n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Uzupełnianie średnią\n",
    "    ('scaler', StandardScaler())                 # Skalowanie danych\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Uzupełnianie najczęstszą wartością\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))     # OneHotEncoder dla kategorii\n",
    "])\n",
    "\n",
    "# Stworzenie ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),      # Numeryczne kolumny\n",
    "        ('cat', categorical_transformer, categorical_features),  # Kategoryczne kolumny\n",
    "    ]\n",
    ")\n",
    "\n",
    "#models pipeline\n",
    "models = {\n",
    "    'Linear Regression': Pipeline(steps=[ #wywołanie Pipeline z dwoma krokami: preprocessor i model\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', LinearRegression()) #stworzenie instancji modelu\n",
    "    ]),\n",
    "    'Random Forest': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestRegressor())\n",
    "    ]),\n",
    "    'XGBoost': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', XGBRegressor())\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 4.390755961409231\n",
      "Random Forest: 0.1528318937132857\n",
      "XGBoost: 0.15283456747451746\n",
      "Best model: Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer()),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  Index([], dtype='object')),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('onehot',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                                  Index(['country', 'store', 'product'], dtype='object'))])),\n",
      "                ('model', RandomForestRegressor())])\n",
      "Best score: 0.1528318937132857\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_score= float('inf')\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = -cross_val_score(model, x, y, cv=5, scoring='neg_mean_absolute_percentage_error')\n",
    "    score = np.mean(scores)\n",
    "    print(f'{name}: {score}')\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_model = model\n",
    "\n",
    "print(f'Best model: {best_model}')\n",
    "print(f'Best score: {best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przekształcenie kolumny daty w zbiorze testowym\n",
    "test['year'] = pd.to_datetime(test['date']).dt.year\n",
    "test['month'] = pd.to_datetime(test['date']).dt.month\n",
    "test['day'] = pd.to_datetime(test['date']).dt.day\n",
    "\n",
    "# Usuń oryginalną kolumnę daty\n",
    "test_prepared = test.drop(columns=['date'])\n",
    "\n",
    "#fitting the best model\n",
    "best_model.fit(x, y)\n",
    "\n",
    "# Użycie najlepszego modelu do przewidywania\n",
    "predictions = best_model.predict(test_prepared)\n",
    "\n",
    "# Jeśli potrzebujesz wyników z kolumną ID:\n",
    "results = pd.DataFrame({\n",
    "    'id': test['id'],  # Pobranie ID z testowego DataFrame\n",
    "    'num_sold': predictions  # Wyniki przewidywań\n",
    "})\n",
    "\n",
    "# Zapisanie wyników do pliku CSV (opcjonalne)\n",
    "results.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id        date    country                 store  \\\n",
      "0            0  2010-01-01     Canada     Discount Stickers   \n",
      "1            1  2010-01-01     Canada     Discount Stickers   \n",
      "2            2  2010-01-01     Canada     Discount Stickers   \n",
      "3            3  2010-01-01     Canada     Discount Stickers   \n",
      "4            4  2010-01-01     Canada     Discount Stickers   \n",
      "...        ...         ...        ...                   ...   \n",
      "230125  230125  2016-12-31  Singapore  Premium Sticker Mart   \n",
      "230126  230126  2016-12-31  Singapore  Premium Sticker Mart   \n",
      "230127  230127  2016-12-31  Singapore  Premium Sticker Mart   \n",
      "230128  230128  2016-12-31  Singapore  Premium Sticker Mart   \n",
      "230129  230129  2016-12-31  Singapore  Premium Sticker Mart   \n",
      "\n",
      "                   product     num_sold  year  month  day  day_of_week  \n",
      "0        Holographic Goose   104.201479  2010      1    1            4  \n",
      "1                   Kaggle   973.000000  2010      1    1            4  \n",
      "2             Kaggle Tiers   906.000000  2010      1    1            4  \n",
      "3                 Kerneler   423.000000  2010      1    1            4  \n",
      "4       Kerneler Dark Mode   491.000000  2010      1    1            4  \n",
      "...                    ...          ...   ...    ...  ...          ...  \n",
      "230125   Holographic Goose   466.000000  2016     12   31            5  \n",
      "230126              Kaggle  2907.000000  2016     12   31            5  \n",
      "230127        Kaggle Tiers  2299.000000  2016     12   31            5  \n",
      "230128            Kerneler  1242.000000  2016     12   31            5  \n",
      "230129  Kerneler Dark Mode  1622.000000  2016     12   31            5  \n",
      "\n",
      "[230130 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wiki2\\AppData\\Local\\Temp\\ipykernel_23412\\2111177391.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_missing['num_sold'] = predicted_values\n"
     ]
    }
   ],
   "source": [
    "# Konwersja kolumny 'date' na cechy numeryczne\n",
    "train_copy['year'] = pd.to_datetime(train_copy['date']).dt.year\n",
    "train_copy['month'] = pd.to_datetime(train_copy['date']).dt.month\n",
    "train_copy['day'] = pd.to_datetime(train_copy['date']).dt.day\n",
    "train_copy['day_of_week'] = pd.to_datetime(train_copy['date']).dt.dayofweek\n",
    "\n",
    "# Podział danych na brakujące i pełne wartości\n",
    "train_filled = train_copy[train_copy['num_sold'].notna()]\n",
    "train_missing = train_copy[train_copy['num_sold'].isna()]\n",
    "\n",
    "# Przygotowanie X i y dla danych bez braków\n",
    "X_train_filled = train_filled.drop(columns=['num_sold', 'id', 'date'])\n",
    "y_train_filled = train_filled['num_sold']\n",
    "\n",
    "# Przygotowanie danych testowych dla brakujących wartości\n",
    "X_train_missing = train_missing.drop(columns=['num_sold', 'id', 'date'])\n",
    "\n",
    "# Dopasowanie pipeline i modelu do danych treningowych\n",
    "best_model.fit(X_train_filled, y_train_filled)\n",
    "\n",
    "# Predykcja dla brakujących wartości\n",
    "predicted_values = best_model.predict(X_train_missing)\n",
    "\n",
    "# Uzupełnienie braków w danych\n",
    "train_missing['num_sold'] = predicted_values\n",
    "\n",
    "# Połączenie danych w całość\n",
    "train_complete = pd.concat([train_filled, train_missing]).sort_index()\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(train_complete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 5.8826629891620215\n",
      "Random Forest: 0.1469615661483103\n",
      "XGBoost: 0.14697052302614383\n",
      "Best model: Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer()),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  Index([], dtype='object')),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('onehot',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                                  Index(['country', 'store', 'product'], dtype='object'))])),\n",
      "                ('model', RandomForestRegressor())])\n",
      "Best score: 0.1469615661483103\n"
     ]
    }
   ],
   "source": [
    "x = train_complete.drop(columns=['id', 'num_sold'], axis=1)\n",
    "y = train_complete['num_sold']\n",
    "\n",
    "numeric_features = x.select_dtypes(include=['int64','float64']).columns\n",
    "categorical_features = x.select_dtypes(include=['object']).columns\n",
    "categorical_features = categorical_features[categorical_features != 'date']\n",
    "\n",
    "\n",
    "\n",
    "# Konwersja kolumny daty na cechy numeryczne\n",
    "x['year'] = pd.to_datetime(x['date']).dt.year\n",
    "x['month'] = pd.to_datetime(x['date']).dt.month\n",
    "x['day'] = pd.to_datetime(x['date']).dt.day\n",
    "\n",
    "# Usuń oryginalną kolumnę daty\n",
    "X = x.drop(columns=['date'])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "#preprocessor \n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Uzupełnianie średnią\n",
    "    ('scaler', StandardScaler())                 # Skalowanie danych\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Uzupełnianie najczęstszą wartością\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))     # OneHotEncoder dla kategorii\n",
    "])\n",
    "\n",
    "# Stworzenie ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),      # Numeryczne kolumny\n",
    "        ('cat', categorical_transformer, categorical_features),  # Kategoryczne kolumny\n",
    "    ]\n",
    ")\n",
    "\n",
    "#models pipeline\n",
    "models = {\n",
    "    'Linear Regression': Pipeline(steps=[ #wywołanie Pipeline z dwoma krokami: preprocessor i model\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', LinearRegression()) #stworzenie instancji modelu\n",
    "    ]),\n",
    "    'Random Forest': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestRegressor())\n",
    "    ]),\n",
    "    'XGBoost': Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', XGBRegressor())\n",
    "    ])\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_model = None\n",
    "best_score= float('inf')\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = -cross_val_score(model, x, y, cv=5, scoring='neg_mean_absolute_percentage_error')\n",
    "    score = np.mean(scores)\n",
    "    print(f'{name}: {score}')\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_model = model\n",
    "\n",
    "print(f'Best model: {best_model}')\n",
    "print(f'Best score: {best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przekształcenie kolumny daty w zbiorze testowym\n",
    "test['year'] = pd.to_datetime(test['date']).dt.year\n",
    "test['month'] = pd.to_datetime(test['date']).dt.month\n",
    "test['day'] = pd.to_datetime(test['date']).dt.day\n",
    "\n",
    "# Usuń oryginalną kolumnę daty\n",
    "test_prepared = test.drop(columns=['date'])\n",
    "\n",
    "#fitting the best model\n",
    "best_model.fit(x, y)\n",
    "\n",
    "# Użycie najlepszego modelu do przewidywania\n",
    "predictions = best_model.predict(test_prepared)\n",
    "\n",
    "# Jeśli potrzebujesz wyników z kolumną ID:\n",
    "results = pd.DataFrame({\n",
    "    'id': test['id'],  # Pobranie ID z testowego DataFrame\n",
    "    'num_sold': predictions  # Wyniki przewidywań\n",
    "})\n",
    "\n",
    "# Zapisanie wyników do pliku CSV (opcjonalne)\n",
    "results.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
